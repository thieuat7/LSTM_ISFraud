{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37033d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, LayerNormalization, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20bdeb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50f4c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Báº®T Äáº¦U Táº O CHUá»–I 3D (CHIáº¾N LÆ¯á»¢C: CLEAN USERS ONLY)\n",
      "ğŸ‘‰ Äang Ä‘á»c dá»¯ liá»‡u...\n",
      "ğŸ‘‰ Äang xÃ¡c Ä‘á»‹nh cÃ¡c tháº» 'sáº¡ch' (chÆ°a tá»«ng bá»‹ gian láº­n)...\n",
      "   - ÄÃ£ tÃ¬m tháº¥y 1,532 tháº» cÃ³ dÃ­nh lÃ­u Ä‘áº¿n gian láº­n.\n",
      "   - Sá»‘ lÆ°á»£ng giao dá»‹ch ban Ä‘áº§u: 472,432\n",
      "   - Sá»‘ lÆ°á»£ng giao dá»‹ch sau khi lá»c sáº¡ch: 117,094\n",
      "   - Tá»· lá»‡ dá»¯ liá»‡u giá»¯ láº¡i: 24.79%\n",
      "ğŸ‘‰ Äang xá»­ lÃ½ nhÃ³m theo 'card1' Ä‘á»ƒ táº¡o chuá»—i...\n",
      "   - ÄÃ£ xá»­ lÃ½ 11000 nhÃ³m...\n",
      "ğŸ‘‰ ÄÃ£ xá»­ lÃ½ xong 11198 nhÃ³m. Äang chuyá»ƒn Ä‘á»•i sang numpy array...\n",
      "\n",
      "âœ… HOÃ€N Táº¤T!\n",
      "ğŸ¯ X_train_3d shape: (67649, 10, 98)\n",
      "   - Sá»‘ máº«u huáº¥n luyá»‡n: 67,649\n",
      "   - Äá»™ dÃ i chuá»—i (Timesteps): 10\n",
      "   - Sá»‘ Ä‘áº·c trÆ°ng (Features): 98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "# =========================================\n",
    "# Cáº¤U HÃŒNH\n",
    "# =========================================\n",
    "FOLDER_NAME = \"processed_data_final_v1\"\n",
    "CSV_FILENAME = \"train_data_optimized.csv\"\n",
    "FEATURE_NAMES_FILE = \"final_feature_list.joblib\"\n",
    "\n",
    "SEQ_LEN = 10\n",
    "GROUP_ID_COL = 'card1'\n",
    "TIME_COL = 'TransactionDT'\n",
    "TARGET_COL = 'isFraud'\n",
    "\n",
    "# =========================================\n",
    "# HÃ€M Há»– TRá»¢\n",
    "# =========================================\n",
    "def create_sequences(data, seq_len):\n",
    "    \"\"\"Táº¡o máº£ng 2D thÃ nh cÃ¡c chuá»—i 3D.\"\"\"\n",
    "    sequences = []\n",
    "    if len(data) >= seq_len:\n",
    "        for i in range(len(data) - seq_len + 1):\n",
    "            window = data[i:(i + seq_len)]\n",
    "            sequences.append(window)\n",
    "    return sequences\n",
    "\n",
    "# =========================================\n",
    "# QUY TRÃŒNH CHÃNH\n",
    "# =========================================\n",
    "print(\"ğŸš€ Báº®T Äáº¦U Táº O CHUá»–I 3D (CHIáº¾N LÆ¯á»¢C: CLEAN USERS ONLY)\")\n",
    "\n",
    "# 1. Táº£i dá»¯ liá»‡u\n",
    "csv_path = os.path.join(FOLDER_NAME, CSV_FILENAME)\n",
    "features_path = os.path.join(FOLDER_NAME, FEATURE_NAMES_FILE)\n",
    "if not os.path.exists(csv_path): raise FileNotFoundError(\"âŒ Thiáº¿u file CSV.\")\n",
    "\n",
    "print(\"ğŸ‘‰ Äang Ä‘á»c dá»¯ liá»‡u...\")\n",
    "df_all = pd.read_csv(csv_path)\n",
    "final_feature_names = joblib.load(features_path)\n",
    "\n",
    "# --- BÆ¯á»šC 2 ÄÆ¯á»¢C NÃ‚NG Cáº¤P ---\n",
    "print(\"ğŸ‘‰ Äang xÃ¡c Ä‘á»‹nh cÃ¡c tháº» 'sáº¡ch' (chÆ°a tá»«ng bá»‹ gian láº­n)...\")\n",
    "# TÃ¬m danh sÃ¡ch cÃ¡c tháº» Ä‘Ã£ tá»«ng cÃ³ Ã­t nháº¥t 1 giao dá»‹ch gian láº­n\n",
    "fraud_cards = df_all[df_all[TARGET_COL] == 1][GROUP_ID_COL].unique()\n",
    "print(f\"   - ÄÃ£ tÃ¬m tháº¥y {len(fraud_cards):,} tháº» cÃ³ dÃ­nh lÃ­u Ä‘áº¿n gian láº­n.\")\n",
    "\n",
    "# Chá»‰ giá»¯ láº¡i cÃ¡c tháº» KHÃ”NG náº±m trong danh sÃ¡ch Ä‘en nÃ y\n",
    "df_clean_users = df_all[~df_all[GROUP_ID_COL].isin(fraud_cards)].copy()\n",
    "print(f\"   - Sá»‘ lÆ°á»£ng giao dá»‹ch ban Ä‘áº§u: {len(df_all):,}\")\n",
    "print(f\"   - Sá»‘ lÆ°á»£ng giao dá»‹ch sau khi lá»c sáº¡ch: {len(df_clean_users):,}\")\n",
    "print(f\"   - Tá»· lá»‡ dá»¯ liá»‡u giá»¯ láº¡i: {len(df_clean_users)/len(df_all)*100:.2f}%\")\n",
    "\n",
    "del df_all; gc.collect() # Dá»n dáº¹p dá»¯ liá»‡u gá»‘c\n",
    "\n",
    "# 3. Chuáº©n bá»‹ columns\n",
    "feature_cols = [c for c in final_feature_names if c not in [GROUP_ID_COL, TIME_COL, TARGET_COL]]\n",
    "cols_to_use = [GROUP_ID_COL, TIME_COL] + feature_cols\n",
    "# Sá»­ dá»¥ng df_clean_users thay vÃ¬ df_normal cÅ©\n",
    "df_processing = df_clean_users[cols_to_use] \n",
    "\n",
    "# 4. Táº¡o chuá»—i (Giá»¯ táº¥t cáº£ trÃªn RAM)\n",
    "print(f\"ğŸ‘‰ Äang xá»­ lÃ½ nhÃ³m theo '{GROUP_ID_COL}' Ä‘á»ƒ táº¡o chuá»—i...\")\n",
    "grouped = df_processing.groupby(GROUP_ID_COL)\n",
    "\n",
    "all_sequences = []\n",
    "count = 0\n",
    "for group_id, group_df in grouped:\n",
    "    group_df_sorted = group_df.sort_values(by=TIME_COL)\n",
    "    feature_data = group_df_sorted[feature_cols].values.astype(np.float32)\n",
    "    \n",
    "    seqs = create_sequences(feature_data, SEQ_LEN)\n",
    "    all_sequences.extend(seqs)\n",
    "    \n",
    "    count += 1\n",
    "    if count % 1000 == 0: print(f\"   - ÄÃ£ xá»­ lÃ½ {count} nhÃ³m...\", end='\\r')\n",
    "\n",
    "print(f\"\\nğŸ‘‰ ÄÃ£ xá»­ lÃ½ xong {count} nhÃ³m. Äang chuyá»ƒn Ä‘á»•i sang numpy array...\")\n",
    "del df_processing, df_clean_users, grouped; gc.collect()\n",
    "\n",
    "# 5. Chuyá»ƒn list thÃ nh numpy array 3D\n",
    "if all_sequences:\n",
    "    X_train_3d = np.array(all_sequences, dtype=np.float32)\n",
    "    print(\"\\nâœ… HOÃ€N Táº¤T!\")\n",
    "    print(f\"ğŸ¯ X_train_3d shape: {X_train_3d.shape}\")\n",
    "    # In thÃªm thÃ´ng tin Ä‘á»ƒ kiá»ƒm tra\n",
    "    print(f\"   - Sá»‘ máº«u huáº¥n luyá»‡n: {X_train_3d.shape[0]:,}\")\n",
    "    print(f\"   - Äá»™ dÃ i chuá»—i (Timesteps): {X_train_3d.shape[1]}\")\n",
    "    print(f\"   - Sá»‘ Ä‘áº·c trÆ°ng (Features): {X_train_3d.shape[2]}\")\n",
    "    del all_sequences; gc.collect()\n",
    "else:\n",
    "    print(\"\\nâŒ Cáº¢NH BÃO: KhÃ´ng táº¡o Ä‘Æ°á»£c chuá»—i nÃ o (cÃ³ thá»ƒ SEQ_LEN quÃ¡ lá»›n).\")\n",
    "    X_train_3d = np.empty((0, SEQ_LEN, len(feature_cols)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a231373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tá»•ng sá»‘ chuá»—i: 67649\n",
      "Sá»‘ chuá»—i huáº¥n luyá»‡n (X_train): 54119\n",
      "Sá»‘ chuá»—i kiá»ƒm tra (X_val): 13530\n",
      "---\n",
      "HÃ¬nh dáº¡ng X_train: (54119, 10, 98)\n",
      "HÃ¬nh dáº¡ng X_val: (13530, 10, 98)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(X_train_3d, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tá»•ng sá»‘ chuá»—i: {len(X_train_3d)}\")\n",
    "print(f\"Sá»‘ chuá»—i huáº¥n luyá»‡n (X_train): {len(X_train)}\")\n",
    "print(f\"Sá»‘ chuá»—i kiá»ƒm tra (X_val): {len(X_val)}\")\n",
    "print(\"---\")\n",
    "print(f\"HÃ¬nh dáº¡ng X_train: {X_train.shape}\")\n",
    "print(f\"HÃ¬nh dáº¡ng X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ab6bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value in X_train: 0.0\n",
      "Max value in X_train: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min value in X_train:\", np.min(X_train))\n",
    "print(\"Max value in X_train:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef627d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(X_train_3d.shape[1])\n",
    "print(X_train_3d.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48e33fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 98\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = X_train_3d.shape[1]\n",
    "INPUT_DIM = X_train_3d.shape[2]\n",
    "print(SEQ_LEN, INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25693fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from train_model_V3 import LSTMAutoencoderTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9bcfa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,728</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_4             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ latent_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,370</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m98\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚        \u001b[38;5;34m41,728\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_4             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ latent_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mTimeDistributed\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m98\u001b[0m)         â”‚         \u001b[38;5;34m6,370\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,530</span> (447.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,530\u001b[0m (447.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,530</span> (447.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,530\u001b[0m (447.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Khá»Ÿi táº¡o trainer\n",
    "trainer = LSTMAutoencoderTrainer(seq_len=SEQ_LEN, input_dim=INPUT_DIM)\n",
    "\n",
    "trainer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e15723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 0.1376 - val_loss: 0.0467\n",
      "Epoch 2/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0390 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0317 - val_loss: 0.0282\n",
      "Epoch 4/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0300 - val_loss: 0.0276\n",
      "Epoch 5/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0296 - val_loss: 0.0270\n",
      "Epoch 6/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0292 - val_loss: 0.0267\n",
      "Epoch 7/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0286 - val_loss: 0.0263\n",
      "Epoch 8/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0281 - val_loss: 0.0251\n",
      "Epoch 9/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0275 - val_loss: 0.0249\n",
      "Epoch 10/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 11/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0268 - val_loss: 0.0241\n",
      "Epoch 12/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0262 - val_loss: 0.0235\n",
      "Epoch 13/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0259 - val_loss: 0.0230\n",
      "Epoch 14/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0253 - val_loss: 0.0226\n",
      "Epoch 15/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0249 - val_loss: 0.0223\n",
      "Epoch 16/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0244 - val_loss: 0.0217\n",
      "Epoch 17/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0239 - val_loss: 0.0209\n",
      "Epoch 18/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 19/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0231 - val_loss: 0.0199\n",
      "Epoch 20/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0226 - val_loss: 0.0195\n",
      "Epoch 21/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0224 - val_loss: 0.0190\n",
      "Epoch 22/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0222 - val_loss: 0.0191\n",
      "Epoch 23/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0219 - val_loss: 0.0188\n",
      "Epoch 24/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0215 - val_loss: 0.0183\n",
      "Epoch 25/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0213 - val_loss: 0.0180\n",
      "Epoch 26/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0212 - val_loss: 0.0180\n",
      "Epoch 27/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0211 - val_loss: 0.0173\n",
      "Epoch 28/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 29/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0209 - val_loss: 0.0176\n",
      "Epoch 30/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0208 - val_loss: 0.0175\n",
      "Epoch 31/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0206 - val_loss: 0.0169\n",
      "Epoch 32/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0203 - val_loss: 0.0166\n",
      "Epoch 33/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0200 - val_loss: 0.0167\n",
      "Epoch 34/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0199 - val_loss: 0.0160\n",
      "Epoch 35/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0198 - val_loss: 0.0168\n",
      "Epoch 36/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0197 - val_loss: 0.0156\n",
      "Epoch 37/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0196 - val_loss: 0.0157\n",
      "Epoch 38/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0195 - val_loss: 0.0154\n",
      "Epoch 39/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0195 - val_loss: 0.0158\n",
      "Epoch 40/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0194 - val_loss: 0.0151\n",
      "Epoch 41/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0193 - val_loss: 0.0151\n",
      "Epoch 42/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0192 - val_loss: 0.0150\n",
      "Epoch 43/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0191 - val_loss: 0.0152\n",
      "Epoch 44/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0190 - val_loss: 0.0148\n",
      "Epoch 45/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0190 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0189 - val_loss: 0.0149\n",
      "Epoch 47/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0188 - val_loss: 0.0143\n",
      "Epoch 48/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0188 - val_loss: 0.0142\n",
      "Epoch 49/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 50/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0187 - val_loss: 0.0142\n",
      "Epoch 51/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0186 - val_loss: 0.0142\n",
      "Epoch 52/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0186 - val_loss: 0.0142\n",
      "Epoch 53/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0185 - val_loss: 0.0141\n",
      "Epoch 54/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0185 - val_loss: 0.0141\n",
      "Epoch 55/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0185 - val_loss: 0.0139\n",
      "Epoch 56/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0184 - val_loss: 0.0144\n",
      "Epoch 57/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0183 - val_loss: 0.0139\n",
      "Epoch 58/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0184 - val_loss: 0.0141\n",
      "Epoch 59/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0182 - val_loss: 0.0140\n",
      "Epoch 60/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0182 - val_loss: 0.0138\n",
      "Epoch 61/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0181 - val_loss: 0.0142\n",
      "Epoch 62/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0181 - val_loss: 0.0135\n",
      "Epoch 63/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0181 - val_loss: 0.0133\n",
      "Epoch 64/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0181 - val_loss: 0.0135\n",
      "Epoch 65/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0181 - val_loss: 0.0136\n",
      "Epoch 66/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0180 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0180 - val_loss: 0.0132\n",
      "Epoch 68/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0180 - val_loss: 0.0131\n",
      "Epoch 69/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0178 - val_loss: 0.0136\n",
      "Epoch 70/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0178 - val_loss: 0.0133\n",
      "Epoch 71/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0179 - val_loss: 0.0133\n",
      "Epoch 72/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0178 - val_loss: 0.0136\n",
      "Epoch 73/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0178 - val_loss: 0.0130\n",
      "Epoch 74/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 75/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 76/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 77/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 78/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0176 - val_loss: 0.0127\n",
      "Epoch 79/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0176 - val_loss: 0.0133\n",
      "Epoch 80/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 82/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 83/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 84/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0174 - val_loss: 0.0129\n",
      "Epoch 85/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 86/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 87/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0172 - val_loss: 0.0133\n",
      "Epoch 88/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0174 - val_loss: 0.0132\n",
      "Epoch 89/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 90/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0172 - val_loss: 0.0127\n",
      "Epoch 91/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 92/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 93/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0174 - val_loss: 0.0134\n",
      "Epoch 94/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - loss: 0.0170 - val_loss: 0.0127\n",
      "Epoch 95/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 96/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 97/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 98/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 99/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 100/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "history = trainer.fit(\n",
    "    X_train=X_train,\n",
    "    X_val=X_val,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    patience=10           # sá»‘ epoch chá» trÆ°á»›c khi dá»«ng sá»›m\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78ef55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to models/lstm_isFraud.keras\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"models/lstm_isFraud.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
